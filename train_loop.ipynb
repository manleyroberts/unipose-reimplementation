{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7N92c2bvSSE"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://8080-5aed7051-8ac7-450f-8a6a-df73d6c6e7a2.cs-us-east1-omte.cloudshell.dev/"
    },
    "id": "ltAS_TXYvSSK",
    "outputId": "b3deed16-1987-4ae7-d6fa-63a988a147da"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from uuid import uuid4\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Check device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: %s\" % device)\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ExUPuFeVvSSL"
   },
   "outputs": [],
   "source": [
    "with open('annotations/valid.json') as f:\n",
    "    test_data = json.load(f)\n",
    "with open('annotations/train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"pose-estimation-2-dc39bc540ba3.json\"\n",
    "    \n",
    "storage_client = storage.Client(\"pose_estimation_2\")\n",
    "bucket = storage_client.get_bucket('pose_estimation_2_dataset_mpii')\n",
    "\n",
    "NUM_TRAIN = 256\n",
    "NUM_TEST = 2958"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBotjUmNvSSM"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OOFhpNErvSSM"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 30\n",
    "learning_rate = 0.0001\n",
    "optimizer_type = 'ADAM'\n",
    "\n",
    "hyperparam_string = f'batch_size: {batch_size}, epochs: {epochs}, lr: {learning_rate}, optimizer: {optimizer_type}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRkFgyn-vSSM"
   },
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pltgIszsvSSM"
   },
   "outputs": [],
   "source": [
    "import modules\n",
    "import gc\n",
    "\n",
    "from modules.unipose import UniPose\n",
    "from modules.criterion.distribution_difference_loss import DistributionDifferenceLoss \n",
    "from modules.criterion.joint_max_mse_loss import JointMaxMSELoss\n",
    "from gaussians import Gaussians\n",
    "\n",
    "model = UniPose().to(device)\n",
    "criterion = DistributionDifferenceLoss(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) if optimizer_type == 'ADAM' else None\n",
    "gaussian = Gaussians()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 1 images\n",
      "Loaded 11 images\n",
      "Loaded 21 images\n",
      "Loaded 31 images\n",
      "Loaded 41 images\n",
      "Loaded 51 images\n",
      "Loaded 61 images\n",
      "Loaded 71 images\n",
      "Loaded 81 images\n",
      "Loaded 91 images\n",
      "Loaded 101 images\n",
      "Loaded 111 images\n",
      "Loaded 121 images\n",
      "Loaded 131 images\n",
      "Loaded 141 images\n",
      "Loaded 151 images\n",
      "Loaded 161 images\n",
      "Loaded 171 images\n",
      "Loaded 181 images\n",
      "Loaded 191 images\n",
      "Loaded 201 images\n",
      "Loaded 211 images\n",
      "Loaded 221 images\n",
      "Loaded 231 images\n",
      "Loaded 241 images\n",
      "Loaded 251 images\n",
      "Image Load:33.69359350204468, Tensor Build:42.36976504325867\n",
      "Loaded 256 images, shape is torch.Size([256, 3, 368, 368]), kpt shape is torch.Size([256, 16, 368, 368])\n"
     ]
    }
   ],
   "source": [
    "load_start = time.time()\n",
    "\n",
    "kpt_list     = []\n",
    "\n",
    "torch_image = torch.zeros(NUM_TRAIN, 368, 368, 3, dtype=torch.half)\n",
    "kpt_tensor = torch.zeros(torch_image.shape, dtype=torch.half)\n",
    "torch_image.requires_grad = False\n",
    "kpt_tensor.requires_grad = False\n",
    "\n",
    "# For each image, load the image\n",
    "for i in range(NUM_TRAIN):\n",
    "    img_name = train_data[i]['image']\n",
    "\n",
    "    blob = bucket.blob('MPII/images/' +  img_name)\n",
    "    blob.content_type = 'image/jpeg'\n",
    "    image = np.asarray(bytearray(blob.download_as_string()))\n",
    "    img = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    kpt = np.asarray(train_data[i]['joints'], dtype=np.int32)\n",
    "\n",
    "    if img.shape[0] != 368 or img.shape[1] != 368:\n",
    "        kpt[:,0] = kpt[:,0] * (368/img.shape[1])\n",
    "        kpt[:,1] = kpt[:,1] * (368/img.shape[0])\n",
    "        img = cv2.resize(img,(368,368))\n",
    "        img = np.array(img)\n",
    "\n",
    "    kpt_list.append(kpt)\n",
    "    torch_image[i,:,:,:] = torch.HalfTensor(img)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f'Loaded {i+1} images')\n",
    "\n",
    "image_load_time = time.time()\n",
    "\n",
    "# construct image tensor and label tensor\n",
    "# torch_image = torch.Tensor(imagelist)\n",
    "torch_image = torch_image.permute(0, 3, 1, 2)\n",
    "expected_maps = gaussian.expected_to_gaussian(kpt_list)\n",
    "torch_image.requires_grad = False\n",
    "expected_maps.requires_grad = False\n",
    "\n",
    "tensor_build_time = time.time()\n",
    "\n",
    "print(f'Image Load:{image_load_time - load_start}, Tensor Build:{tensor_build_time - image_load_time}')\n",
    "print(f'Loaded {NUM_TRAIN} images, shape is {torch_image.shape}, kpt shape is {expected_maps.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_torch_image, val_torch_image = train_test_split(torch_image, test_size = 0.25)\n",
    "train_expected_maps, val_expected_maps = train_test_split(expected_maps, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, criterion, optimizer, train_torch_image, train_expected_maps, batch_size):\n",
    "    epoch_loss = []\n",
    "    # For each batch\n",
    "    for start_i in range(0, len(train_torch_image), batch_size):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "#         torch_image_batch = torch_image[ start_i: start_i + batch_size ,:,:,:].to(device)\n",
    "#         map_batch         = expected_maps[ start_i: start_i + batch_size ,:,:]\n",
    "        \n",
    "        # Loading in the training images from train/test splits\n",
    "        torch_image_batch = train_torch_image[ start_i: start_i + batch_size ,:,:,:].to(torch.float32).to(device)\n",
    "        map_batch         = train_expected_maps[ start_i: start_i + batch_size ,:,:].to(torch.float32).to(device)\n",
    "\n",
    "        tensor_transfer_time = time.time()\n",
    "        \n",
    "        # Train on batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(torch_image_batch)\n",
    "\n",
    "        forward_pass_time = time.time()\n",
    "        \n",
    "        batch_loss = criterion(out, map_batch)\n",
    "        \n",
    "        loss_function_time = time.time()\n",
    "        \n",
    "        epoch_loss.append(batch_loss.item())\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        \n",
    "        backprop_time = time.time()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer_time = time.time()\n",
    "\n",
    "#         print(f'Epoch: {epoch}, Batch: {start_i // batch_size}, Batch Distribution Difference Loss: {batch_loss}, JointMaxMSELoss (to see if model is working): {alt_criterion(out, kpt_batch.to(device))}')\n",
    "        print(f'Epoch: {epoch}, Batch: {start_i // batch_size}, Training Batch Distribution Difference Loss: {batch_loss}')\n",
    "        print(f'Tensor Transfer:{tensor_transfer_time - start_time}, Forward:{forward_pass_time - tensor_transfer_time}, Criterion:{loss_function_time - forward_pass_time}')\n",
    "        print(f'Backward:{backprop_time - loss_function_time}, Optimizer_Step:{optimizer_time - backprop_time}, Total:{optimizer_time - start_time}')\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, model, criterion, val_torch_image, val_expected_maps, batch_size):\n",
    "    epoch_loss = []\n",
    "    # For each batch\n",
    "    for start_i in range(0, len(val_torch_image), batch_size):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "#         torch_image_batch = torch_image[ start_i: start_i + batch_size ,:,:,:].to(device)\n",
    "#         map_batch         = expected_maps[ start_i: start_i + batch_size ,:,:]\n",
    "        \n",
    "        # Loading in the training images from train/test splits\n",
    "        torch_image_batch = val_torch_image[ start_i: start_i + batch_size ,:,:,:].to(device)\n",
    "        map_batch         = val_expected_maps[ start_i: start_i + batch_size ,:,:].to(device)\n",
    "\n",
    "        tensor_transfer_time = time.time()\n",
    "        \n",
    "        # Train on batch\n",
    "        with torch.no_grad():\n",
    "            out = model(torch_image_batch)\n",
    "\n",
    "            forward_pass_time = time.time()\n",
    "\n",
    "            batch_loss = criterion(out, map_batch)\n",
    "\n",
    "            loss_function_time = time.time()\n",
    "            \n",
    "        epoch_loss.append(batch_loss.item())\n",
    "\n",
    "            \n",
    "#         print(f'Epoch: {epoch}, Batch: {start_i // batch_size}, Batch Distribution Difference Loss: {batch_loss}, JointMaxMSELoss (to see if model is working): {alt_criterion(out, kpt_batch.to(device))}')\n",
    "        print(f'Epoch: {epoch}, Batch: {start_i // batch_size}, Validation Batch Distribution Difference Loss: {batch_loss}')\n",
    "        print(f'Tensor Transfer:{tensor_transfer_time - start_time}, Forward:{forward_pass_time - tensor_transfer_time}, Criterion:{loss_function_time - forward_pass_time}')\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://8080-5aed7051-8ac7-450f-8a6a-df73d6c6e7a2.cs-us-east1-omte.cloudshell.dev/"
    },
    "id": "kXks1wtZvSSN",
    "outputId": "01c17f06-4970-48c9-c86b-d330c47aba80"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 68.00 MiB (GPU 0; 4.00 GiB total capacity; 2.45 GiB already allocated; 49.40 MiB free; 2.51 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fbc7e68b2720>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtrain_epoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_torch_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_expected_maps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mval_epoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_torch_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_expected_maps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-fe054d2fa95d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, model, criterion, optimizer, train_torch_image, train_expected_maps, batch_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_image_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mforward_pass_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Manley\\projects\\cs7643\\unipose-reimplementation\\modules\\unipose.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mfinal_feats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_level_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mwasp_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwasp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_feats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwasp_feats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_level_feats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Manley\\projects\\cs7643\\unipose-reimplementation\\modules\\resnet_wrapper.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mlayer1_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs7643-a1\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 68.00 MiB (GPU 0; 4.00 GiB total capacity; 2.45 GiB already allocated; 49.40 MiB free; 2.51 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train_epoch_losses = []\n",
    "val_epoch_losses = []\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "uuid_string = str(datetime.datetime.now())\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_epoch_loss = train(epoch, model, criterion, optimizer, train_torch_image, train_expected_maps, batch_size)\n",
    "    val_epoch_loss = validation(epoch, model, criterion, val_torch_image, val_expected_maps, batch_size)\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Training Average Batch Loss: {sum(train_epoch_loss) / len(train_epoch_loss)}')\n",
    "    print(f'Epoch: {epoch}, Validation Average Batch Loss: {sum(val_epoch_loss) / len(val_epoch_loss)}')\n",
    "    \n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "    val_epoch_losses.append(val_epoch_loss)\n",
    "    \n",
    "    with open(f'epoch{epoch}.txt', 'a') as f:\n",
    "        print(hyperparam_string, file=f)\n",
    "        for e in range(epoch + 1):\n",
    "            print(f'Epoch: {e}, Training Average Batch Loss: {sum(train_epoch_losses[e]) / len(train_epoch_losses[e])}', file=f)\n",
    "            print(f'Epoch: {e}, Validation Average Batch Loss: {sum(val_epoch_losses[e]) / len(val_epoch_losses[e])}', file=f)\n",
    "        print(f'Epoch: {e}, Training Epoch Losses: {train_epoch_losses}', file=f)\n",
    "        print(f'Epoch: {e}, Validation Epoch Loss: {val_epoch_losses}', file=f)\n",
    "        \n",
    "    f_name = f'epoch{epoch}.txt'\n",
    "    blob = bucket.blob(f\"training_output/{uuid_string}/epoch{epoch}.txt\")\n",
    "    blob.upload_from_filename(f_name)\n",
    "    os.remove(f_name)\n",
    "        \n",
    "    f_name = f'epoch{epoch}.pkl'\n",
    "    pickle.dump(model, open(f_name, 'wb'))\n",
    "    \n",
    "    blob = bucket.blob(f\"training_output/{uuid_string}/epoch{epoch}.pkl\")\n",
    "    blob.upload_from_filename(f_name)\n",
    "    os.remove(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_name = 'finalized_model.pkl'\n",
    "pickle.dump(model, open(f_name, 'wb'))\n",
    "\n",
    "blob = bucket.blob(f\"training_output/{uuid_string}/final.pkl\")\n",
    "blob.upload_from_filename(f_name)\n",
    "os.remove(f_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_loop.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "kernelspec": {
   "name": "python385jvsc74a57bd0f5157702e1d47db57ea0e093a2e40a1bada3468c5f50b6dfb56109f5e3115d0b",
   "display_name": "Python 3.8.5 64-bit ('cs7643-a1': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}