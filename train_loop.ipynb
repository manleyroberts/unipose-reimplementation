{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7N92c2bvSSE"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://8080-5aed7051-8ac7-450f-8a6a-df73d6c6e7a2.cs-us-east1-omte.cloudshell.dev/"
    },
    "id": "ltAS_TXYvSSK",
    "outputId": "b3deed16-1987-4ae7-d6fa-63a988a147da"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "from uuid import uuid4\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.stdout = open(\"my_log.txt\", \"a\")\n",
    "\n",
    "# Check device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: %s\" % device)\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ExUPuFeVvSSL"
   },
   "outputs": [],
   "source": [
    "with open('annotations/valid.json') as f:\n",
    "    test_data = json.load(f)\n",
    "with open('annotations/train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\"\n",
    "    \n",
    "storage_client = storage.Client(\"pose_estimation_2\")\n",
    "bucket = storage_client.get_bucket('pose_estimation_2_dataset_mpii')\n",
    "\n",
    "NUM_TRAIN = 22246\n",
    "NUM_TEST = 2958"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBotjUmNvSSM"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OOFhpNErvSSM"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 30\n",
    "learning_rate = 0.0001\n",
    "optimizer_type = 'ADAM'\n",
    "\n",
    "hyperparam_string = f'batch_size: {batch_size}, epochs: {epochs}, lr: {learning_rate}, optimizer: {optimizer_type}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRkFgyn-vSSM"
   },
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pltgIszsvSSM"
   },
   "outputs": [],
   "source": [
    "import modules\n",
    "import gc\n",
    "\n",
    "from modules.unipose import UniPose\n",
    "from modules.criterion.distribution_difference_loss import DistributionDifferenceLoss \n",
    "from modules.criterion.joint_max_mse_loss import JointMaxMSELoss\n",
    "from gaussians import Gaussians\n",
    "\n",
    "model = UniPose().to(device)\n",
    "criterion = DistributionDifferenceLoss(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) if optimizer_type == 'ADAM' else None\n",
    "gaussian = Gaussians()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_start = time.time()\n",
    "\n",
    "kpt_list     = []\n",
    "\n",
    "torch_image = torch.zeros(NUM_TRAIN, 368, 368, 3, dtype=torch.half)\n",
    "torch_image.requires_grad = False\n",
    "\n",
    "# For each image, load the image\n",
    "for i in range(NUM_TRAIN):\n",
    "    img_name = train_data[i]['image']\n",
    "\n",
    "    blob = bucket.blob('MPII/images/' +  img_name)\n",
    "    blob.content_type = 'image/jpeg'\n",
    "    image = np.asarray(bytearray(blob.download_as_string()))\n",
    "    img = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    kpt = np.asarray(train_data[i]['joints'], dtype=np.int32)\n",
    "\n",
    "    if img.shape[0] != 368 or img.shape[1] != 368:\n",
    "        kpt[:,0] = kpt[:,0] * (368/img.shape[1])\n",
    "        kpt[:,1] = kpt[:,1] * (368/img.shape[0])\n",
    "        img = cv2.resize(img,(368,368))\n",
    "        img = np.array(img)\n",
    "\n",
    "    kpt_list.append(kpt)\n",
    "    torch_image[i,:,:,:] = torch.HalfTensor(img)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f'Loaded {i+1} images')\n",
    "\n",
    "image_load_time = time.time()\n",
    "\n",
    "# construct image tensor and label tensor\n",
    "# torch_image = torch.Tensor(imagelist)\n",
    "torch_image = torch_image.permute(0, 3, 1, 2)\n",
    "expected_maps = gaussian.expected_to_gaussian(kpt_list)\n",
    "torch_image.requires_grad = False\n",
    "expected_maps.requires_grad = False\n",
    "\n",
    "tensor_build_time = time.time()\n",
    "\n",
    "print(f'Image Load:{image_load_time - load_start}, Tensor Build:{tensor_build_time - image_load_time}')\n",
    "print(f'Loaded {NUM_TRAIN} images, shape is {torch_image.shape}, kpt shape is {expected_maps.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_torch_image, val_torch_image = train_test_split(torch_image, test_size = 0.25)\n",
    "train_expected_maps, val_expected_maps = train_test_split(expected_maps, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, criterion, optimizer, train_torch_image, train_expected_maps, batch_size):\n",
    "    epoch_loss = []\n",
    "    # For each batch\n",
    "    for start_i in range(0, len(train_torch_image), batch_size):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "#         torch_image_batch = torch_image[ start_i: start_i + batch_size ,:,:,:].to(device)\n",
    "#         map_batch         = expected_maps[ start_i: start_i + batch_size ,:,:]\n",
    "        \n",
    "        # Loading in the training images from train/test splits\n",
    "        torch_image_batch = train_torch_image[ start_i: start_i + batch_size ,:,:,:].to(device).to(torch.float32)\n",
    "        map_batch         = train_expected_maps[ start_i: start_i + batch_size ,:,:].to(device).to(torch.float32)\n",
    "\n",
    "        tensor_transfer_time = time.time()\n",
    "        \n",
    "        # Train on batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(torch_image_batch)\n",
    "\n",
    "        forward_pass_time = time.time()\n",
    "        \n",
    "        batch_loss = criterion(out, map_batch)\n",
    "        \n",
    "        loss_function_time = time.time()\n",
    "        \n",
    "        epoch_loss.append(batch_loss.item())\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        \n",
    "        backprop_time = time.time()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer_time = time.time()\n",
    "\n",
    "#         print(f'Epoch: {epoch}, Batch: {start_i // batch_size}, Batch Distribution Difference Loss: {batch_loss}, JointMaxMSELoss (to see if model is working): {alt_criterion(out, kpt_batch.to(device))}')\n",
    "        print(f'Epoch: {epoch}, Batch: {start_i // batch_size}, Training Batch Distribution Difference Loss: {batch_loss}')\n",
    "        print(f'Tensor Transfer:{tensor_transfer_time - start_time}, Forward:{forward_pass_time - tensor_transfer_time}, Criterion:{loss_function_time - forward_pass_time}')\n",
    "        print(f'Backward:{backprop_time - loss_function_time}, Optimizer_Step:{optimizer_time - backprop_time}, Total:{optimizer_time - start_time}')\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, model, criterion, val_torch_image, val_expected_maps, batch_size):\n",
    "    epoch_loss = []\n",
    "    # For each batch\n",
    "    for start_i in range(0, len(val_torch_image), batch_size):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "#         torch_image_batch = torch_image[ start_i: start_i + batch_size ,:,:,:].to(device)\n",
    "#         map_batch         = expected_maps[ start_i: start_i + batch_size ,:,:]\n",
    "        \n",
    "        # Loading in the training images from train/test splits\n",
    "        torch_image_batch = val_torch_image[ start_i: start_i + batch_size ,:,:,:].to(device).to(torch.float32)\n",
    "        map_batch         = val_expected_maps[ start_i: start_i + batch_size ,:,:].to(device).to(torch.float32)\n",
    "\n",
    "        tensor_transfer_time = time.time()\n",
    "        \n",
    "        # Train on batch\n",
    "        with torch.no_grad():\n",
    "            out = model(torch_image_batch)\n",
    "\n",
    "            forward_pass_time = time.time()\n",
    "\n",
    "            batch_loss = criterion(out, map_batch)\n",
    "\n",
    "            loss_function_time = time.time()\n",
    "            \n",
    "        epoch_loss.append(batch_loss.item())\n",
    "\n",
    "            \n",
    "#         print(f'Epoch: {epoch}, Batch: {start_i // batch_size}, Batch Distribution Difference Loss: {batch_loss}, JointMaxMSELoss (to see if model is working): {alt_criterion(out, kpt_batch.to(device))}')\n",
    "        print(f'Epoch: {epoch}, Batch: {start_i // batch_size}, Validation Batch Distribution Difference Loss: {batch_loss}')\n",
    "        print(f'Tensor Transfer:{tensor_transfer_time - start_time}, Forward:{forward_pass_time - tensor_transfer_time}, Criterion:{loss_function_time - forward_pass_time}')\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://8080-5aed7051-8ac7-450f-8a6a-df73d6c6e7a2.cs-us-east1-omte.cloudshell.dev/"
    },
    "id": "kXks1wtZvSSN",
    "outputId": "01c17f06-4970-48c9-c86b-d330c47aba80"
   },
   "outputs": [],
   "source": [
    "train_epoch_losses = []\n",
    "val_epoch_losses = []\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "uuid_string = str(datetime.datetime.now())\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_epoch_loss = train(epoch, model, criterion, optimizer, train_torch_image, train_expected_maps, batch_size)\n",
    "    val_epoch_loss = validation(epoch, model, criterion, val_torch_image, val_expected_maps, batch_size)\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Training Average Batch Loss: {sum(train_epoch_loss) / len(train_epoch_loss)}')\n",
    "    print(f'Epoch: {epoch}, Validation Average Batch Loss: {sum(val_epoch_loss) / len(val_epoch_loss)}')\n",
    "    \n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "    val_epoch_losses.append(val_epoch_loss)\n",
    "    \n",
    "    with open(f'epoch{epoch}.txt', 'a') as f:\n",
    "        print(hyperparam_string, file=f)\n",
    "        for e in range(epoch + 1):\n",
    "            print(f'Epoch: {e}, Training Average Batch Loss: {sum(train_epoch_losses[e]) / len(train_epoch_losses[e])}', file=f)\n",
    "            print(f'Epoch: {e}, Validation Average Batch Loss: {sum(val_epoch_losses[e]) / len(val_epoch_losses[e])}', file=f)\n",
    "        print(f'Epoch: {e}, Training Epoch Losses: {train_epoch_losses}', file=f)\n",
    "        print(f'Epoch: {e}, Validation Epoch Loss: {val_epoch_losses}', file=f)\n",
    "        \n",
    "    f_name = f'epoch{epoch}.txt'\n",
    "    blob = bucket.blob(f\"training_output/{uuid_string}/epoch{epoch}.txt\")\n",
    "    blob.upload_from_filename(f_name)\n",
    "    os.remove(f_name)\n",
    "        \n",
    "    f_name = f'epoch{epoch}.pkl'\n",
    "    pickle.dump(model, open(f_name, 'wb'))\n",
    "    \n",
    "    blob = bucket.blob(f\"training_output/{uuid_string}/epoch{epoch}.pkl\")\n",
    "    blob.upload_from_filename(f_name)\n",
    "    os.remove(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_name = 'finalized_model.pkl'\n",
    "pickle.dump(model, open(f_name, 'wb'))\n",
    "\n",
    "blob = bucket.blob(f\"training_output/{uuid_string}/final.pkl\")\n",
    "blob.upload_from_filename(f_name)\n",
    "os.remove(f_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_loop.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}